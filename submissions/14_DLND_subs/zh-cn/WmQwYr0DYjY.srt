1
00:00:00,980 --> 00:00:02,870
你好 欢迎回来

2
00:00:02,870 --> 00:00:05,929
这周我要讲的是

3
00:00:05,929 --> 00:00:07,649
迁移学习

4
00:00:07,650 --> 00:00:12,679
实际上大多数人不会亲自去用巨大的数据集

5
00:00:12,679 --> 00:00:15,019
来训练大型神经网络

6
00:00:15,019 --> 00:00:17,449
比如说  你在训练

7
00:00:17,449 --> 00:00:20,250
一个卷积网络 例如使用 ImageNet 数据集

8
00:00:20,250 --> 00:00:24,739
训练 AlexNet 等网络 你需要使用多个图形处理器

9
00:00:24,739 --> 00:00:24,740
以及花费数周时间使用
训练 AlexNet 等网络 你需要使用多个图形处理器

10
00:00:24,740 --> 00:00:26,119
以及花费数周时间使用

11
00:00:26,120 --> 00:00:29,449
而大多数人并没有

12
00:00:29,449 --> 00:00:29,450
这样的时间和资源
而大多数人并没有

13
00:00:29,450 --> 00:00:31,250
这样的时间和资源

14
00:00:31,250 --> 00:00:34,520
所以 你可以找一个训练好的网络

15
00:00:34,520 --> 00:00:36,670
像 AlexNet

16
00:00:36,670 --> 00:00:40,979
然后加以修改 用于解决你自己的问题

17
00:00:40,979 --> 00:00:40,980
比如 你有一些图像
然后加以修改 用于解决你自己的问题

18
00:00:40,980 --> 00:00:43,549
比如 你有一些图像

19
00:00:43,549 --> 00:00:47,000
你想进行分类或者做目标检测

20
00:00:47,000 --> 00:00:50,509
你可以下载像 AlexNet 或 VGGNet

21
00:00:50,509 --> 00:00:54,829
这样已经训练好的网络 然后将它们用作

22
00:00:54,829 --> 00:00:57,409
特征提取器来实际抓取

23
00:00:57,409 --> 00:00:59,569
你图像中的特征

24
00:00:59,570 --> 00:01:01,250
然后大概要做的就是

25
00:01:01,250 --> 00:01:05,040
选中最后几个全连接层

26
00:01:05,040 --> 00:01:08,359
它们基本上相当于分类器 对吧？

27
00:01:08,359 --> 00:01:10,609
然后你直接从网络中移除它们

28
00:01:10,609 --> 00:01:13,590
将自己的分类器加上去

29
00:01:13,590 --> 00:01:16,219
在这个notebook里面，我会让你使用

30
00:01:16,219 --> 00:01:19,429
迁移学习 对新的数据集

31
00:01:19,430 --> 00:01:22,189
进行图像分类

32
00:01:22,189 --> 00:01:22,190
我们将使用 VGGNet 架构
进行图像分类

33
00:01:22,190 --> 00:01:26,239
我们将使用 VGGNet 架构

34
00:01:26,239 --> 00:01:30,289
我找到了一个训练好的 VGGNet

35
00:01:30,290 --> 00:01:34,790
的 GitHub 代码库 我们直接抓取使用就可以了

36
00:01:34,790 --> 00:01:39,500
VGGNet 背后的思路基本就是这样

37
00:01:39,500 --> 00:01:41,000
你可以看到它的架构

38
00:01:41,000 --> 00:01:43,123
可以看到我们有了一堆卷积层、

39
00:01:43,123 --> 00:01:46,081
一个最大池化层、卷积层、最大池化层、卷积层

40
00:01:46,081 --> 00:01:47,039
最大池化层等等

41
00:01:47,040 --> 00:01:51,230
所以我们共有五个这种类型的卷积层叠加在一起

42
00:01:51,230 --> 00:01:54,109
最后在结尾处 我们有三个全连接层

43
00:01:54,109 --> 00:01:56,885
然后是一个用于分类的 softmax 函数

44
00:01:56,885 --> 00:02:00,140
那么 我们要做的是将这些卷积层

45
00:02:00,140 --> 00:02:01,700
用作特征提取器

46
00:02:01,700 --> 00:02:04,310
然后丢弃这些全连接层

47
00:02:04,310 --> 00:02:08,419
加上我们自己的分类器 这样我们就可以为我们的新图像

48
00:02:08,419 --> 00:02:10,439
训练分类器了

49
00:02:10,439 --> 00:02:12,979
那么在这里 在所有这些卷积层之后的

50
00:02:12,979 --> 00:02:15,409
这个全连接层

51
00:02:15,409 --> 00:02:19,310
它是拥有 4,096 个单元的层

52
00:02:19,310 --> 00:02:23,060
然后我们可以把所有经过激活函数后的单元当作

53
00:02:23,060 --> 00:02:24,539
一段编码 对吧？

54
00:02:24,539 --> 00:02:26,659
所以这就像一段卷积编码

55
00:02:26,659 --> 00:02:30,259
我们可以把它用作分类器的输入

56
00:02:30,259 --> 00:02:33,049
那么我们这里的目标是

57
00:02:33,050 --> 00:02:34,546
提取我们新数据集里的每个图像 在这些

58
00:02:34,545 --> 00:02:36,169
卷积层中传递它 并且获取

59
00:02:36,169 --> 00:02:38,849
这一层的代码

60
00:02:38,849 --> 00:02:41,900
这是你稍后要实施的操作

61
00:02:41,900 --> 00:02:43,969
你可以从 CS231N 的课程讲义中

62
00:02:43,969 --> 00:02:47,569
读到有关迁移学习的更多知识以及关于迁移学习

63
00:02:47,569 --> 00:02:49,689
的其他方法

64
00:02:49,689 --> 00:02:50,840
这些讲义是很好的资源

65
00:02:50,840 --> 00:02:52,699
如果你想更多地了解这一主题

66
00:02:52,699 --> 00:02:52,700
一定要记得查阅我刚提到的资源
如果你想更多地了解这一主题

67
00:02:52,700 --> 00:02:55,369
一定要记得查阅我刚提到的资源

68
00:02:55,370 --> 00:02:57,710
对于此次实现

69
00:02:57,710 --> 00:03:02,250
我们将使用此代码库中的代码

70
00:03:02,250 --> 00:03:04,250
即 TensorFlow VVG

71
00:03:04,250 --> 00:03:09,289
这是一个已训练过的 VVG 网络

72
00:03:09,289 --> 00:03:13,259
你可以下载它的参数

73
00:03:13,259 --> 00:03:17,269
那么你实际上需要做的 就是在开始前

74
00:03:17,270 --> 00:03:18,439
克隆此代码库

75
00:03:18,439 --> 00:03:20,650
那么在下面这个单元

76
00:03:20,650 --> 00:03:23,340
你就可以下载

77
00:03:23,340 --> 00:03:25,889
此模型的参数

78
00:03:25,889 --> 00:03:25,890
确保你一定要执行这一步
此模型的参数

79
00:03:25,890 --> 00:03:28,039
确保你一定要执行这一步

80
00:03:28,039 --> 00:03:31,639
那么要下载 先将代码库克隆

81
00:03:31,639 --> 00:03:34,129
到此 notebook 所在的同一个文件夹

82
00:03:34,129 --> 00:03:35,750
然后用它将参数下载到

83
00:03:35,750 --> 00:03:37,340
同一个文件夹

84
00:03:37,340 --> 00:03:40,129
这样就创建成功了

85
00:03:40,129 --> 00:03:42,799
这一次我们要

86
00:03:42,800 --> 00:03:45,259
对花朵的图像进行分类

87
00:03:45,259 --> 00:03:45,260
这个数据集实际上来自 TensorFlow Inception 的
对花朵的图像进行分类

88
00:03:45,260 --> 00:03:50,569
这个数据集实际上来自 TensorFlow Inception 的

89
00:03:50,569 --> 00:03:52,451
迁移学习教程

90
00:03:52,451 --> 00:03:54,409
我要使用一个与他们不同的网络

91
00:03:54,409 --> 00:03:56,060
但是我抓取相同的数据集

92
00:03:56,060 --> 00:03:59,060
我发现这是学习深度学习的一个好方法

93
00:03:59,060 --> 00:04:02,189
因为如果你知道一个数据集适合用于你自己的问题

94
00:04:02,189 --> 00:04:04,349
但是你又想尝试不同的想法

95
00:04:04,349 --> 00:04:07,349
通常一个好的做法是 每次只改变一样

96
00:04:07,349 --> 00:04:10,473
所以如果我知道数据集是有用的 那么当出现问题时

97
00:04:10,473 --> 00:04:12,139
我就会知道问题出在网络

98
00:04:12,139 --> 00:04:13,909
而不是数据集本身

99
00:04:13,909 --> 00:04:16,250
这就是为什么我选择使用这个花朵数据集

100
00:04:16,250 --> 00:04:18,439
你可以在这里读到更多信息

101
00:04:18,439 --> 00:04:20,689
你可以观看、阅读使用他们的 Interception 网络

102
00:04:20,689 --> 00:04:24,709
进行迁移学习的教程

103
00:04:24,709 --> 00:04:27,859
这里是我们下载数据集的地方

104
00:04:27,860 --> 00:04:30,490
它会帮你完成下载工作

